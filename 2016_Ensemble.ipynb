{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9R7mE08OBxNl","executionInfo":{"status":"ok","timestamp":1715347327494,"user_tz":-480,"elapsed":17876,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"539c4610-089e-4833-bdec-a4eeb90d32c4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import tempfile\n","\n","directory = \"/content/drive/MyDrive/Colab Notebooks/ELEC4840/Project/Ensemble/\"\n","\n","root_dir = tempfile.mkdtemp() if directory is None else directory\n","os.chdir(root_dir)\n","os.listdir('.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNsc6QBEB9e5","executionInfo":{"status":"ok","timestamp":1715347333123,"user_tz":-480,"elapsed":957,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"8016cbc6-d67d-4ed7-8827-007d10af20fe"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data', '__pycache__', 'models', 'utils', '2016_Ensemble.ipynb']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3jBYGT87BfHk","executionInfo":{"status":"ok","timestamp":1715347342365,"user_tz":-480,"elapsed":3914,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}}},"outputs":[],"source":["import torch\n","from torchsummary import summary"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L5SZPlELBfHp","executionInfo":{"status":"ok","timestamp":1715347378820,"user_tz":-480,"elapsed":2378,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}}},"outputs":[],"source":["from utils.setup import *\n","from utils.training import *\n","from utils.visualise import *\n","\n","from models.models_resnet import *\n","from models.models_alexnet import *\n","from models.models_vgg19 import *"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoRNaT8IBfHq","executionInfo":{"status":"ok","timestamp":1715347396209,"user_tz":-480,"elapsed":408,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"d2ea1101-b9cf-4922-a218-187314dc8792"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train folder exists: True\n","Val folder exists: True\n","Test folder exists: True\n"]}],"source":["setup_directory(\"/content/drive/MyDrive/Colab Notebooks/ELEC4840/Project/Ensemble/\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1SZVMs-bBfHr","executionInfo":{"status":"ok","timestamp":1715347408662,"user_tz":-480,"elapsed":10099,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"4a652e7f-9ea8-4d49-cc87-b76a53e64f35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in 'train': 862\n","Number of files in 'val': 322\n","Number of files in 'test': 379\n"]}],"source":["print(\"Number of files in 'train':\", count_files('./data/train'))\n","print(\"Number of files in 'val':\", count_files('./data/val'))\n","print(\"Number of files in 'test':\", count_files('./data/test'))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2N5ikIPUBfHs","executionInfo":{"status":"ok","timestamp":1715344140135,"user_tz":-480,"elapsed":43,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}}},"outputs":[],"source":["root_train, root_val, root_test = './data/train', './data/val', './data/test'\n","loader_train, loader_val, loader_test = get_train_test_set(root_train, root_val, root_test)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"7fhMLkmeBfHs","executionInfo":{"status":"ok","timestamp":1715347567321,"user_tz":-480,"elapsed":314,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPHxu_dsBfHs","executionInfo":{"status":"ok","timestamp":1715344184892,"user_tz":-480,"elapsed":44798,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"96abfec5-057e-4a47-fb9f-9f28b10e4c22"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 55, 55]          34,944\n","              ReLU-2           [-1, 96, 55, 55]               0\n","         MaxPool2d-3           [-1, 96, 27, 27]               0\n","            Conv2d-4          [-1, 256, 27, 27]         614,656\n","              ReLU-5          [-1, 256, 27, 27]               0\n","         MaxPool2d-6          [-1, 256, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         885,120\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n","             ReLU-10          [-1, 384, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         884,992\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","          Flatten-14                 [-1, 9216]               0\n","           Linear-15                 [-1, 4096]      37,752,832\n","             ReLU-16                 [-1, 4096]               0\n","          Dropout-17                 [-1, 4096]               0\n","           Linear-18                 [-1, 4096]      16,781,312\n","             ReLU-19                 [-1, 4096]               0\n","          Dropout-20                 [-1, 4096]               0\n","           Linear-21                    [-1, 2]           8,194\n","================================================================\n","Total params: 58,289,538\n","Trainable params: 0\n","Non-trainable params: 58,289,538\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 11.11\n","Params size (MB): 222.36\n","Estimated Total Size (MB): 234.04\n","----------------------------------------------------------------\n"]}],"source":["model_2017 = AlexNet(input_channel=3, n_classes=2)\n","\n","model_2017.load_state_dict(torch.load(\"models/2017_alexnet_model.pth\", map_location=torch.device('cpu')))\n","\n","for param in model_2017.parameters():\n","    param.requires_grad = False\n","\n","model_2017.to(device)\n","\n","summary(model_2017, input_size=(3, 224, 224))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFCACdCJBfHt","executionInfo":{"status":"ok","timestamp":1715347573555,"user_tz":-480,"elapsed":3595,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"ced1d214-5ed7-4c4b-e66d-1989b9d90b85"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           1,792\n","              ReLU-2         [-1, 64, 224, 224]               0\n","            Conv2d-3         [-1, 64, 224, 224]          36,928\n","              ReLU-4         [-1, 64, 224, 224]               0\n","         MaxPool2d-5         [-1, 64, 112, 112]               0\n","            Conv2d-6        [-1, 128, 112, 112]          73,856\n","              ReLU-7        [-1, 128, 112, 112]               0\n","            Conv2d-8        [-1, 128, 112, 112]         147,584\n","              ReLU-9        [-1, 128, 112, 112]               0\n","        MaxPool2d-10          [-1, 128, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]         295,168\n","             ReLU-12          [-1, 256, 56, 56]               0\n","           Conv2d-13          [-1, 256, 56, 56]         590,080\n","             ReLU-14          [-1, 256, 56, 56]               0\n","           Conv2d-15          [-1, 256, 56, 56]         590,080\n","             ReLU-16          [-1, 256, 56, 56]               0\n","        MaxPool2d-17          [-1, 256, 28, 28]               0\n","           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n","             ReLU-19          [-1, 512, 28, 28]               0\n","           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n","             ReLU-21          [-1, 512, 28, 28]               0\n","           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n","             ReLU-23          [-1, 512, 28, 28]               0\n","        MaxPool2d-24          [-1, 512, 14, 14]               0\n","           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n","             ReLU-26          [-1, 512, 14, 14]               0\n","           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n","             ReLU-28          [-1, 512, 14, 14]               0\n","           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n","             ReLU-30          [-1, 512, 14, 14]               0\n","        MaxPool2d-31            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                    [-1, 2]           8,194\n","================================================================\n","Total params: 134,268,738\n","Trainable params: 8,194\n","Non-trainable params: 134,260,544\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 218.77\n","Params size (MB): 512.19\n","Estimated Total Size (MB): 731.54\n","----------------------------------------------------------------\n"]}],"source":["model_2018 = VGG19()\n","\n","model_2018.load_state_dict(torch.load(\"models/2018_vgg19_model.pth\", map_location=torch.device('cpu')))\n","\n","for param in model_2018.parameters():\n","    param.requires_grad = False\n","\n","model_2018.to(device)\n","\n","summary(model_2018, input_size=(3, 224, 224))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfUmEitpBfHt","executionInfo":{"status":"ok","timestamp":1715347672613,"user_tz":-480,"elapsed":7009,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"af54511b-7b61-483f-dcf7-fd73eb605176"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 133MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n","      Bottleneck-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n","      Bottleneck-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n","      Bottleneck-172           [-1, 2048, 7, 7]               0\n","       AvgPool2d-173           [-1, 2048, 1, 1]               0\n","          ResNet-174                 [-1, 2048]               0\n","          Linear-175                    [-1, 2]           4,098\n","================================================================\n","Total params: 23,512,130\n","Trainable params: 0\n","Non-trainable params: 23,512,130\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.57\n","Params size (MB): 89.69\n","Estimated Total Size (MB): 376.83\n","----------------------------------------------------------------\n"]}],"source":["resnet50 = get_resnet50(pre_trained=True)\n","model_2019 = ClassificationModel(resnet50, 2)\n","\n","model_2019.load_state_dict(torch.load(\"models/2019_resnet_model.pth\", map_location=torch.device('cpu')))\n","\n","for param in model_2019.parameters():\n","    param.requires_grad = False\n","\n","model_2019.to(device)\n","\n","summary(model_2019, input_size=(3, 224, 224))"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, roc_auc_score\n","import numpy as np\n","from tqdm import tqdm\n","\n","y_pred1 = []\n","y_pred2 = []\n","y_pred3 = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for inputs, labels in tqdm(loader_train):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        pred1 = model_2017(inputs)[:, 0]\n","        pred2 = model_2018(inputs)[:, 0]\n","        pred3 = model_2018(inputs)[:, 0]\n","\n","        y_pred1.extend(np.around(pred1.cpu().numpy()))\n","        y_pred2.extend(np.around(pred2.cpu().numpy()))\n","        y_pred3.extend(np.around(pred3.cpu().numpy()))\n","        y_true.extend(labels.cpu().numpy())\n","\n","        y_pred1 = [0 if pred < 0 else pred for pred in y_pred1]\n","        y_pred2 = [0 if pred < 0 else pred for pred in y_pred2]\n","        y_pred3 = [0 if pred < 0 else pred for pred in y_pred3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxOIsO_bKBTc","executionInfo":{"status":"ok","timestamp":1715345747203,"user_tz":-480,"elapsed":47691,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"91cd6622-f5b9-4796-dbd8-eaae3df676d0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 54/54 [00:47<00:00,  1.13it/s]\n"]}]},{"cell_type":"code","source":["from scipy.stats import mode\n","\n","maxvoted_pred = []\n","for i in range(len(y_pred1)):\n","    ensemble_pred = mode([y_pred1[i], y_pred2[i], y_pred3[i]])[0]\n","    maxvoted_pred.append(ensemble_pred)\n","\n","accuracy_maxvoted = accuracy_score(y_true, maxvoted_pred)\n","auc_maxvoted = roc_auc_score(y_true, maxvoted_pred)\n","\n","print(\"Max Voted Ensemble Accuracy:\", accuracy_maxvoted)\n","print(\"Max Voted Ensemble AUC:\", auc_maxvoted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLmrXkaZhqmM","executionInfo":{"status":"ok","timestamp":1715345950502,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tara Relan","userId":"00717747575335442507"}},"outputId":"6383f419-2dcc-40a4-b67b-4e9bd8052ee7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Max Voted Ensemble Accuracy: 0.8951044083526681\n","Max Voted Ensemble AUC: 0.9111293591445944\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}